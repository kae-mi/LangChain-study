{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain \n",
    "- Chain은 LangChain에서 여러 컴포넌트를 연결하여 복잡한 작업을 수행할 수 있게 해주는 개념이다.\n",
    "- 왜 쓰는가?\n",
    "    - 간결한 코드 작성: 여러 단계의 작업을 파이프라인으로 연결하여 코드를 더 간결하게 작성할 수 있습다.\n",
    "    - 재사용성: 만들어진 체인을 다른 체인의 일부로 재사용할 수 있다.\n",
    "    - 모듈화: 복잡한 워크플로우를 작은 단위로 나누어 관리할 수 있다.\n",
    "- 사용 방법\n",
    "    - `capital_chain = prompt_template | llm | output_parser`\n",
    "    - 각 컴포넌트를파이프(|) 연산자로 연결한다.\n",
    "    - 그렇게 되면, 왼쪽 컴포넌트의 출력이 오른쪽 컴포넌트의 입력으로 전달된다.\n",
    "    - 체인 실행은 `invoke()` 메서드를 이용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-04T14:42:27.4366521Z', 'done': True, 'done_reason': 'stop', 'total_duration': 369743700, 'load_duration': 15248300, 'prompt_eval_count': 32, 'prompt_eval_duration': 38851100, 'eval_count': 8, 'eval_duration': 315121500, 'model_name': 'llama3.2:1b'}, id='run--93ca73d0-728d-488b-b4c0-212af3d0ecbf-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"What is te capital of {country}?\n",
    "    Return the capital name only.\"\"\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"country\": \"France\"})\n",
    "\n",
    "ai_message = llm.invoke(prompt)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "answer = output_parser.invoke(ai_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위의 여러 줄로 작성한 코드를 하나의 체인으로 만들어서 실행시킬 수 있다.\n",
    "- `capital_chain = prompt_template | llm | output_parser`\n",
    "- prompt_template 의 결과가 llm 으로 전달되고, llm 의 결과가 output_parser 로 전달된다. 실행 결과는 모두 Runnable이기 때문에 가능한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_chain = prompt_template | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 실행하는 방법은 여러 가지가 있는데, 가장 쉬운 방법은 invoke 메서드를 사용하는 것이다.\n",
    "# 체인의 결과는 Runnable이기 때문에 다른 Runnable을 인자로 전달할 수 있다.\n",
    "capital_chain.invoke({\"country\": \"France\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나라 이름을 응답으로 주는 country_template를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# country_prompt 는 나라 이름을 응답으로 주는 프롬프트이다.\n",
    "\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"Guess the name of the country based on the following information:\n",
    "    {information}\n",
    "    Return the country name only.\n",
    "    \"\"\",\n",
    "    input_variables=[\"information\"],\n",
    ")\n",
    "\n",
    "# country_chain 은 country_prompt 를 실행하고, llm 을 실행하고, output_parser 를 실행한다.\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "\n",
    "# 체인을 실행하면 나라 이름을 응답으로 준다.\n",
    "country_chain.invoke({\"information\": \"This country is very famous for its wine in Europe.\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final_chain 을 만들어보자.\n",
    "- final_chain 은 country_chain의 결과를 capital_chain에 전달하여 최종적으로 결과를 얻는 체인이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_chain의 결과를 capital_chain에 전달하여 최종 결과를 얻는다.\n",
    "\n",
    "# 아래 코드에서 country 에는 country_chain의 결과가 저장되고, 그 값이 그대로 capital_chain에 전달된다.\n",
    "final_chain = {\"country\": country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berlin'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_chain 체인을 실행하면 수도 이름을 응답으로 준다.\n",
    "final_chain.invoke({\"information\": \"This country is very famous for its wine in Europe.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
